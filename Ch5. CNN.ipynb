{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch5. 합성곱 신경망(Convolution Neural Network) \n",
    "\n",
    "## 5.2 합성곱의 연산 과정\n",
    "\n",
    "filter ( kernel이라 부릅니다)를 움직여가며 곱->합->평균으로 다음 셀에 넘김\n",
    "\n",
    "필터의 이동 단위 : Stride\n",
    "\n",
    "필터당 입력 이미지 전체에 대한 일치 정도를 활성화지도( activation map, feature map )\n",
    "\n",
    "feature map의 크기 $ O = floor \\left( \\frac{I - K}{S} + 1 \\right) $ with 이미지 크기 $ I $, 필터 크기 $K$, 스트라이드 $ S $\n",
    "\n",
    "활성화 함수 ReLU, ricky ReLU, randomized ricky ReLU 에 대한 설명이 있었어요\n",
    "\n",
    "## 5.3 패딩과 풀링 (Padding and pooling)\n",
    "\n",
    "패딩 : feture map의 크기와 원 이미지의 크기를 일치시키기 위해 바깥쪽에 넣는 임의 값, 이미지가 충분히 크다면 굳이 필요 x\n",
    "\n",
    " $ O = floor \\left( \\frac{I - K + 2P }{S} + 1 \\right) $ with 이미지 크기 $ I $, 필터 크기 $K$, 패딩 크기 $P$, 스트라이드 $ S $\n",
    " \n",
    "풀링(Pooling = downsampling = subsampling) : 큰 이미지를 작게\n",
    "\n",
    "Max Pooling or Avg Pooling\n",
    "\n",
    "## 5.4 모델의 3차원적 이해\n",
    "\n",
    "$ l \\times m $ 의 이미지에 n개 필터를 적용하면 다음 레이어에서는 $ l \\times m \\times n $ 짜리 박스가 만들어진다는 관점\n",
    "\n",
    "가로 세로는 풀링을 통해 줄어들고 필터 갯수에 따라 채널 수가 늘어나며\n",
    "\n",
    "충분히 특성을 뽑아냈다고 판단되면 완전연결 레이어를 적용해서 가로 x 세로 x 채널의 하나의 벡터가 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 softMax 함수\n",
    "\n",
    "분류하려는 클래스 갯수에 따라 binary vector로 만드는 방법 : one-hot encoding\n",
    "\n",
    "각 클래스에 대한 확률 값을 나타내는 함수 = softmax func\n",
    "\n",
    "\\begin{align}\n",
    "softmax \\left(y_i \\right) = \\frac{ exp( y_i ) }{ \\sum_j{exp(y_j)}}\n",
    "\\end{align}\n",
    "\n",
    "softmax 사용시 손실 측정 법 : cross entropy (교차 엔트로피)\n",
    "\\begin{align}\n",
    "엔트로피 H \\left( p \\right) = - \\sum_{x} {p \\left( x \\right) \\log p \\left( x \\right) }\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "교차 엔트로피 H \\left( p, q \\right) = - \\sum_{x} {p \\left( x \\right) \\log q \\left( x \\right) }\n",
    "\\end{align}\n",
    "\n",
    "교차 엔트로피가 크다라는 것은 최적의 상태보다 더 많은 비트가 필요하다는 뜻 \n",
    "\\begin{align}\n",
    "교차 엔트로피 H \\left( p, q \\right) = H \\left( p \\right) + \\sum_{x} {p \\left( x \\right) \\log \\frac{p \\left( x \\right)} {q \\left( x \\right)} }\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\qquad \\qquad \\qquad = H \\left( p \\right) + D_{KL} \\left( p \\parallel q \\right)\n",
    "\\end{align}\n",
    "\n",
    "KLD(Kullback-Leibler divergence, 쿨러-라이블러 발산) 항 : 분포 p를 기준으로 q가 얼마나 다른지 측정하는 방법\n",
    "\n",
    "KLD을 최소화하는 방향으로 학습. L1norm보다 더 손실에 민감함.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 모델 구현, 학습 및 결과 확인 : MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "#torchvision : 영상처리용 데이터셋, 모델, 이미지 변환기 등\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "#데이터를 하나씩 보내지 않고 batch size별로 전달하기 위해서 필요\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████▊| 9887744/9912422 [00:47<00:00, 392990.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                        | 0/28881 [00:00<?, ?it/s]\n",
      " 57%|█████████████████████████████████████████▍                               | 16384/28881 [00:00<00:00, 66240.81it/s]\n",
      "32768it [00:00, 46736.13it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/1648877 [00:01<?, ?it/s]\n",
      "  1%|▋                                                                      | 16384/1648877 [00:01<01:02, 26117.25it/s]\n",
      "  2%|█▊                                                                     | 40960/1648877 [00:02<00:53, 30291.80it/s]\n",
      "  3%|██                                                                     | 49152/1648877 [00:02<01:05, 24322.30it/s]\n",
      "  6%|████▏                                                                  | 98304/1648877 [00:03<00:46, 33034.87it/s]\n",
      "  9%|██████▌                                                               | 155648/1648877 [00:03<00:34, 43477.80it/s]\n",
      " 13%|█████████▍                                                            | 221184/1648877 [00:05<00:33, 42012.77it/s]\n",
      " 17%|████████████▏                                                         | 286720/1648877 [00:05<00:24, 56621.28it/s]\n",
      " 21%|██████████████▉                                                       | 352256/1648877 [00:05<00:17, 74656.66it/s]\n",
      " 25%|█████████████████▍                                                    | 409600/1648877 [00:05<00:13, 95208.76it/s]\n",
      " 30%|████████████████████▌                                                | 491520/1648877 [00:06<00:09, 120540.44it/s]\n",
      " 35%|████████████████████████▎                                            | 581632/1648877 [00:06<00:06, 153199.12it/s]\n",
      " 42%|████████████████████████████▊                                        | 688128/1648877 [00:06<00:05, 188123.31it/s]\n",
      " 48%|█████████████████████████████████▎                                   | 794624/1648877 [00:06<00:03, 229573.14it/s]\n",
      " 55%|██████████████████████████████████████                               | 909312/1648877 [00:07<00:02, 275809.53it/s]\n",
      " 62%|██████████████████████████████████████████▏                         | 1024000/1648877 [00:07<00:02, 284752.07it/s]\n",
      " 73%|█████████████████████████████████████████████████▎                  | 1196032/1648877 [00:07<00:01, 372595.74it/s]\n",
      "9920512it [01:00, 392990.67it/s]                                                                                       \n",
      " 82%|████████████████████████████████████████████████████████▌            | 1351680/1648877 [00:10<00:03, 78793.92it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▏       | 1458176/1648877 [00:11<00:01, 101888.95it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████▏ | 1605632/1648877 [00:11<00:00, 136452.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|                                                                                         | 0/4542 [00:00<?, ?it/s]\n",
      "\n",
      "8192it [00:00, 18375.57it/s]                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:30, 136452.99it/s]                                                                                       "
     ]
    }
   ],
   "source": [
    "#MNIST : 28 * 28 숫자 이미지\n",
    "\n",
    "mnist_train = dset.MNIST(\"./\",train=True, transform=transforms.ToTensor(), target_transform = None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\",train=False, transform=transforms.ToTensor(), target_transform = None, download=True)\n",
    "\n",
    "#transform : 이미지에 대한 변형, target_tansform : 라벨에 대한 변형(그대로 쓸거임)\n",
    "#다운로드는 현재 경로에 없을 경우 다운로드한다는 뜻\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2,drop_last=True)\n",
    "\n",
    "#뱃치만큼 로드할거고 num_workers는 프로세스 개수 drop_last : 묶고 남는 데이터 버릴지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train,\"\\n\")\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5), # in, out, kernel : mnist가 batch, 1, 28, 28이라 in은 1 out은 16, kernel은 임의로 5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), #kernel, stride\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.fc_layer=nn.Sequential(\n",
    "            nn.Linear(64*3*3,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x) # construct한 모델에 데이터를 넣은 결과\n",
    "        out = out.view(batch_size,-1) # -1은 -1인 부분은 알아서 계산하라는 뜻\n",
    "        out = self.fc_layer(out) # DNN으로 10개 class중 하나로\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 텐서 : [batch_size, in_channels, 가로, 세로]\n",
    "\n",
    "합성곱 연산 이후 : [batch_size, out_channels, 가로, 세로]\n",
    "\n",
    "첫번째 Conv2d에서는 입력이 [batch, 1, 28, 28]이었고 $ O = floor \\left( \\frac{I-K+2P}{S} +1 \\right) = floor \\left( \\frac{28-5+2 \\times 0}{1} +1 \\right) = 24 $. 따라서 출력은 [batch, 16, 24,24]. 비슷하게 이후엔 [batch, 32, 20, 20]\n",
    "\n",
    "MaxPool을 통과한 이후엔 [batch, 32, 10, 10] 다시 Conv2d 통과하면 [batch, 64, 6, 6] MaxPool 통과하면 [batch, 64, 3, 3]\n",
    "\n",
    "views는 텐서를 펼쳐서 보겠다는 함수\n",
    "\n",
    "이후에 DNN으로 확률보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #adam 알고리즘으로 옵티마이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr=[]\n",
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_arr.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        if j%1000 == 0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data : 98.828125\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): #기울기를 계산하지 않는 조건에서\n",
    "    for image,label in test_loader :\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        _,output_index = torch.max(output,1) #최댓값과 그 인수 (언팩킹시 특정값 무시하고 싶으면 언더바 쓴대)\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += (output_index ==y_).sum().float()\n",
    "        \n",
    "    print(\"Accuracy of Test Data : {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 유명한 모델들과 원리\n",
    "\n",
    "### VGGNet\n",
    "\n",
    "신경망의 깊이의 영향만을 파악하기 위해 Conv2D(3,3), Max Pooling, DNN 만을 사용해서 모델을 구성, 2014년 2위\n",
    "\n",
    "11~19개 레이어로 실험을 진행.\n",
    "\n",
    "https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "일반적으로 더 깊을 수록 정확도 올라감\n",
    "\n",
    "자체구현시 미리 모델 일부를 함수로 짜놓으면 반복되는 부분을 줄일 수 있음\n",
    "\n",
    "torchvision 공식 코드에서는 class에 \\_\\_init\\_\\_ , forward, initialize\\_weights, make\\_layers 함수를 구현해두고 각 레이어의 필터 수 또는 맥스풀링 여부만 가져와서 layer 구성하는 방식으로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n",
    "\n",
    "2014년 1위, 인셉션 모듈이라는 블록을 쓰기 때문에 인셉션 네트워크라고도 불림\n",
    "\n",
    "인셉션 모듈 : 이전 단계의 활성화 지도에서 다양한 필터($1\\times1 , 3\\times3 , 5\\times5 $)로 Conv \n",
    "\n",
    "https://arxiv.org/pdf/1409.4842v1.pdf\n",
    "\n",
    "$ 1\\times1 $ Conv를 통해 차원감소를 더함 : 입력 채널과 결과 채널 간의 DNN이라고 할 수 있음\n",
    "\n",
    "Conv 곱이 가로세로 어느 위치든 동일하게 적용되기 때문에 연산량을 줄여줌 \n",
    "\n",
    "기존에 128 -> 256 에서 128 -> 32 -> 256으로 \n",
    "\n",
    "또한 Training에서 보조 분류기 (모델 중간에 softmax output을 줘서)를 둬서 네트워크 중간의 정보 손실을 메꾸는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "2015년 1위. 네트워크가 일정 수준 이상의 깊이가 되면 오히려 얕은 모델보다 성능이 떨어짐을 발견\n",
    "\n",
    "이 문제를 해결하기 위해 residual learning(잔차 학습)을 도입. \n",
    "\n",
    "특정 위치에서 입력이 들어왔을때 합성곱 연산을 통과한 결과와 입력으로 들어온 결과 두가지를 더해서 다음 레이어에 전달하는 것.\n",
    "\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n",
    "\n",
    "입력의 단순한 특성과 합성곱 이후의 복잡한 특성 모두를 전달한다는 특성 : $ x_{n+1} = F(x_n) + x_n $ : 기울기도 1\n",
    "\n",
    "$ 1\\times1 $ Conv -> $ 3\\times3 $ -> $ 1\\times1 $ -> $+$ 이런 부분을 bottleneck block이라고 불렀음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그 외\n",
    "\n",
    "GoogleNet + ResNet + batch Regularization = Inception v4\n",
    "\n",
    "ResNet의 잔차 학습을 channel 방향으로 붙이고 연결을 좀더 dense하게한 DenseNet 등\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
